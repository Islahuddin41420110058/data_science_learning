#LIBRARY
import pandas as pd
import matplotlib.pyplot as plt
import re 
import gradio as gr
import sqlite3
from flask import request, Flask, jsonify
from flasgger import Swagger, LazyString, LazyJSONEncoder
from flasgger import swag_from
from assist_code_file import *
from assist_code_text import *

#API PROCESS
app = Flask(__name__)

app.json_encoder = LazyJSONEncoder
swagger_template = dict(
    info = {
        'title': LazyString(lambda:'API documentation for Data Processing and Modeling'),
        'version': LazyString(lambda:'1.0.0'),
        'description': LazyString(lambda:'Dokumentasi Untuk Data Processing dan Modelling'),
    },
    host = LazyString(lambda: request.host)
    )
swagger_config = {
    "headers": [],
    "specs":[
        {
            "endpoint": 'docs',
            "route": '/docs.json',
        }
    ],
    "static_url_path":'/flasgger_static',
    "swagger_ui":True,
    "specs_route":"/docs/"
}

swagger = Swagger(app, template=swagger_template, config=swagger_config)

#Untuk pemanggilan data di swagger Method GET
@swag_from('docs/hello_world.yml', methods=['GET'])
@app.route('/hello_world', methods=['GET'])
def hello_world():
    json_response={
        'status_code': 200,
        'description':'create hello world text',
        'data':'hello world'
    }

    response_data = jsonify(json_response)
    return response_data

#Untuk pemanggilan data di swagger Method POST
@swag_from("docs/text_processing.yml", methods=['POST'])
@app.route('/text_processing', methods=['POST'])
def text_processing():    
    text = request.form.get('text')
    json_response = { 
        'status_code':200, 
        'description':'teks yang sudah diproses', 
        'data':preprocess(text),
        }

    response_data = jsonify(json_response)
    return response_data

#Processing File
@swag_from("docs/file_processing.yml", methods=['POST'])
@app.route('/text_processing_file', methods=['POST'])
def text_processing_file():
    text = request.files.getlist('file')[0] # pemanggilan data dari format yaml

    data_abusive = pd.read_csv('abusive.csv')
    data_alay = pd.read_csv('new_kamusalay.csv', encoding='iso-8859-1',header=None)
    data_alay =data_alay.rename(columns={0: 'original', 1: 'replacement'})

    
    data_alay_new_map = dict(zip(data_alay['original'], data_alay['replacement']))
    
    #merubah kata kata alay menjadi kata kata baku
    def normalize_alay(text):
        return ' '.join([data_alay_new_map[word] if word in data_alay_new_map else word for word in text.split(' ')])

    def preprocess(text):
        text = lowercase(text) # 1
        text = remove_nonaplhanumeric(text) # 2
        text = remove_unnecessary_char(text) # 2
        text = normalize_alay(text) # 3
        return text

    df_new = pd.DataFrame()
    df_data = pd.read_csv(text, encoding='iso-8859-1')
    df_new['old_tweet'] = df_data['Tweet']

    #mengaplikasikan fungsi preprocess
    df_data['Tweet'] = df_data['Tweet'].apply(preprocess)
    df_new['new_tweet'] = df_data['Tweet']

    #export to csv for new file after cleansing
    df_new.to_csv('output_filename.csv', sep=',')

    json_response = { 
        'status_code':200, 
        'description':'file yang sudah diproses', 
        'data': 'success'
        }

    response_data = jsonify(json_response)
    return response_data

if __name__ == '__main__':
    app.run()

